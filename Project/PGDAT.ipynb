{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, argparse, time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import SGD, Adam, lr_scheduler\n",
    "\n",
    "from models.cifar10.resnet import ResNet34\n",
    "from models.svhn.wide_resnet import WRN16_8\n",
    "from models.stl10.wide_resnet import WRN40_2\n",
    "\n",
    "from dataloaders.cifar10 import cifar10_dataloaders\n",
    "from dataloaders.svhn import svhn_dataloaders\n",
    "from dataloaders.stl10 import stl10_dataloaders\n",
    "\n",
    "from utils.utils import *\n",
    "from utils.context import ctx_noparamgrad_and_eval\n",
    "from attacks.pgd import PGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = 0\n",
    "cpus = 8\n",
    "dataset = 'cifar10' #choices=['cifar10', 'svhn', 'stl10']\n",
    "batch_size = 128\n",
    "epochs = 100\n",
    "decay_epochs = [50, 150]\n",
    "opt = 'sgd' #choices=['sgd', 'adam']\n",
    "decay = 'cos' #choices=['cos', 'multisteps']\n",
    "lr = 0.1\n",
    "momentum = 0.9\n",
    "wd = 5e-4 #weight decay\n",
    "targeted = True #if true, targeted attack\n",
    "eps = 31\n",
    "steps =7\n",
    "Lambda = 0.5\n",
    "resume = True #If true, resume from early stopped ckpt\n",
    "efficient = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = gpu\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == 'cifar10':\n",
    "    train_loader, val_loader, _ = cifar10_dataloaders(train_batch_size=batch_size, num_workers=cpus)\n",
    "elif dataset == 'svhn':\n",
    "    train_loader, val_loader, _ = svhn_dataloaders(train_batch_size=batch_size, num_workers=cpus)\n",
    "elif dataset == 'stl10':\n",
    "    train_loader, val_loader = stl10_dataloaders(train_batch_size=batch_size, num_workers=cpus)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == 'cifar10':\n",
    "    model_fn = ResNet34\n",
    "elif dataset == 'svhn':\n",
    "    model_fn = WRN16_8\n",
    "elif dataset == 'stl10':\n",
    "    model_fn = WRN40_2\n",
    "model = model_fn().cuda()\n",
    "model = torch.nn.DataParallel(model)\n",
    "\n",
    "model_str = model_fn.__name__\n",
    "if opt == 'sgd':\n",
    "    opt_str = 'e%d-b%d_sgd-lr%s-m%s-wd%s' % (epochs, batch_size, lr, momentum, wd)\n",
    "elif opt == 'adam':\n",
    "    opt_str = 'e%d-b%d_adam-lr%s-wd%s' % (epochs, batch_size, lr, wd)\n",
    "if decay == 'cos':\n",
    "    decay_str = 'cos'\n",
    "elif decay == 'multisteps':\n",
    "    decay_str = 'multisteps-%s' % decay_epochs\n",
    "attack_str = 'targeted' if targeted else 'untargeted' + '-pgd-%d-%d' % (eps, steps)\n",
    "loss_str = 'lambda%s' % (Lambda)\n",
    "save_folder = os.path.join(os.getcwd(), 'PGD_results', dataset, model_str, '%s_%s_%s_%s' % (attack_str, opt_str, decay_str, loss_str))\n",
    "create_dir(save_folder)\n",
    "\n",
    "if opt == 'sgd':\n",
    "    optimizer = SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=wd)\n",
    "elif opt == 'adam':\n",
    "    optimizer = Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "if decay == 'cos':\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "elif decay == 'multisteps':\n",
    "    scheduler = lr_scheduler.MultiStepLR(optimizer, decay_epochs, gamma=0.1)\n",
    "\n",
    "attacker = PGD(eps=eps/1000, steps=steps)\n",
    "\n",
    "if resume:\n",
    "    last_epoch, best_TA, best_ATA, training_loss, val_TA, val_ATA \\\n",
    "         = load_ckpt(model, optimizer, scheduler, os.path.join(save_folder, 'latest.pth'))\n",
    "    start_epoch = last_epoch + 1\n",
    "else:\n",
    "    start_epoch = 0\n",
    "    best_TA, best_ATA = 0, 0\n",
    "    # training curve lists:\n",
    "    training_loss, val_TA, val_ATA = [], [], []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(start_epoch, epochs):\n",
    "    fp = open(os.path.join(save_folder, 'train_log.txt'), 'a+')\n",
    "    start_time = time.time()\n",
    "\n",
    "    model.train()\n",
    "    requires_grad_(model, True)\n",
    "    accs, accs_adv, losses = AverageMeter(), AverageMeter(), AverageMeter()\n",
    "    for i, (imgs, labels) in enumerate(train_loader):\n",
    "        imgs, labels = imgs.cuda(), labels.cuda()\n",
    "\n",
    "        if Lambda != 0:\n",
    "            with ctx_noparamgrad_and_eval(model):\n",
    "                imgs_adv = attacker.attack(model, imgs, labels)\n",
    "            logits_adv = model(imgs_adv.detach())\n",
    "\n",
    "        logits = model(imgs)\n",
    "\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "        if Lambda != 0:\n",
    "            loss = (1-Lambda) * loss + Lambda * F.cross_entropy(logits_adv, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        current_lr = scheduler.get_lr()[0]\n",
    "\n",
    "        accs.append((logits.argmax(1) == labels).float().mean().item())\n",
    "        if Lambda != 0:\n",
    "            accs_adv.append((logits_adv.argmax(1) == labels).float().mean().item())\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            train_str = 'Epoch %d-%d | Train | Loss: %.4f, SA: %.4f' % (epoch, i, losses.avg, accs.avg)\n",
    "            if Lambda != 0:\n",
    "                train_str += ', RA: %.4f' % (accs_adv.avg)\n",
    "            print(train_str)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    model.eval()\n",
    "    requires_grad_(model, False)\n",
    "    print(model.training)\n",
    "\n",
    "    if dataset == 'cifar10':\n",
    "        eval_this_epoch = (epoch % 10 == 0) or (epoch>=int(0.7*epochs))\n",
    "    elif dataset == 'svhn':\n",
    "        eval_this_epoch = (epoch % 10 == 0) or (epoch>=int(0.25*epochs))\n",
    "    \n",
    "    if eval_this_epoch:\n",
    "        val_accs, val_accs_adv = AverageMeter(), AverageMeter()\n",
    "        for i, (imgs, labels) in enumerate(val_loader):\n",
    "            imgs, labels = imgs.cuda(), labels.cuda()\n",
    "\n",
    "            with ctx_noparamgrad_and_eval(model):\n",
    "                imgs_adv = attacker.attack(model, imgs, labels)\n",
    "            linf_norms = (imgs_adv - imgs).view(imgs.size()[0], -1).norm(p=np.Inf, dim=1)\n",
    "            logits_adv = model(imgs_adv.detach())\n",
    "\n",
    "            logits = model(imgs)\n",
    "\n",
    "            val_accs.append((logits.argmax(1) == labels).float().mean().item())\n",
    "            val_accs_adv.append((logits_adv.argmax(1) == labels).float().mean().item())\n",
    "\n",
    "        val_str = 'Epoch %d | Validation | Time: %.4f | lr: %s | SA: %.4f, RA: %.4f, linf: %.4f - %.4f' % (\n",
    "            epoch, (time.time()-start_time), current_lr, val_accs.avg, val_accs_adv.avg, \n",
    "            torch.min(linf_norms).data, torch.max(linf_norms).data)\n",
    "        print(val_str)\n",
    "        fp.write(val_str + '\\n')\n",
    "\n",
    "\n",
    "    training_loss.append(losses.avg)\n",
    "    plt.plot(training_loss)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss')\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(save_folder, 'training_loss.png'))\n",
    "    plt.close()\n",
    "\n",
    "    if eval_this_epoch:\n",
    "        val_TA.append(val_accs.avg) \n",
    "        plt.plot(val_TA, 'r')\n",
    "        val_ATA.append(val_accs_adv.avg)\n",
    "        plt.plot(val_ATA, 'g')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.title('Validation Accuracy')\n",
    "        plt.legend([\"SA\", \"RA\"])\n",
    "        plt.grid(True)\n",
    "        plt.savefig(os.path.join(save_folder, 'val_acc.png'))\n",
    "        plt.close()\n",
    "    else:\n",
    "        val_TA.append(val_TA[-1]) \n",
    "        plt.plot(val_TA, 'r')\n",
    "        val_ATA.append(val_ATA[-1])\n",
    "        plt.plot(val_ATA, 'g')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.title('Validation Accuracy')\n",
    "        plt.legend([\"SA\", \"RA\"])\n",
    "        plt.grid(True)\n",
    "        plt.savefig(os.path.join(save_folder, 'val_acc.png'))\n",
    "        plt.close()\n",
    "\n",
    "    if eval_this_epoch:\n",
    "        if val_accs.avg >= best_TA:\n",
    "            best_TA = val_accs.avg\n",
    "            torch.save(model.state_dict(), os.path.join(save_folder, 'best_SA.pth'))\n",
    "        if val_accs_adv.avg >= best_ATA:\n",
    "            best_ATA = val_accs_adv.avg\n",
    "            torch.save(model.state_dict(), os.path.join(save_folder, 'best_RA.pth'))\n",
    "    save_ckpt(epoch, model, optimizer, scheduler, best_TA, best_ATA, training_loss, val_TA, val_ATA, \n",
    "        os.path.join(save_folder, 'latest.pth'))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
